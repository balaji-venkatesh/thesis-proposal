 @inproceedings{Abeydeera_Sanchez_2020, address={Lausanne Switzerland}, title={Chronos: Efficient Speculative Parallelism for Accelerators}, ISBN={9781450371025}, url={https://dl.acm.org/doi/10.1145/3373376.3378454}, DOI={10.1145/3373376.3378454}, publisher={ACM}, author={Abeydeera, Maleen and Sanchez, Daniel}, year={2020}, month=mar, pages={1247–1262}, language={en} }
 @article{Aksenov_Alistarh_Korhonen_2021, title={Relaxed Scheduling for Scalable Belief Propagation}, url={http://arxiv.org/abs/2002.11505}, abstractNote={The ability to leverage large-scale hardware parallelism has been one of the key enablers of the accelerated recent progress in machine learning. Consequently, there has been considerable effort invested into developing efficient parallel variants of classic machine learning algorithms. However, despite the wealth of knowledge on parallelization, some classic machine learning algorithms often prove hard to parallelize efficiently while maintaining convergence. In this paper, we focus on efficient parallel algorithms for the key machine learning task of inference on graphical models, in particular on the fundamental belief propagation algorithm. We address the challenge of efficiently parallelizing this classic paradigm by showing how to leverage scalable relaxed schedulers in this context. We present an extensive empirical study, showing that our approach outperforms previous parallel belief propagation implementations both in terms of scalability and in terms of wall-clock convergence time, on a range of practical applications.}, note={arXiv:2002.11505 [cs, stat]}, author={Aksenov, Vitaly and Alistarh, Dan and Korhonen, Janne H.}, year={2021}, month=jan }
 @book{Bishop_2006, address={New York}, series={Information science and statistics}, title={Pattern recognition and machine learning}, ISBN={9780387310732}, callNumber={Q327 .B52 2006}, publisher={Springer}, author={Bishop, Christopher M.}, year={2006}, collection={Information science and statistics} }
 @book{Chen_McCabe_Hyatt_2017, address={Vancouver, Canada}, title={A Belief Network to Predict Safety Performance of Construction Workers}, url={https://csce.ca/elf/apps/CONFERENCEVIEWER/conferences/2017/pdfs/CONSPEC/FinalPaper_145.pdf}, institution={University of Toronto}, author={Chen, Yuting and McCabe, Brenda and Hyatt, Douglas}, year={2017}, month=jun }
 @article{Elidan_McGraw_Koller_2012, title={Residual Belief Propagation: Informed Scheduling for Asynchronous Message Passing}, url={http://arxiv.org/abs/1206.6837}, abstractNote={Inference for probabilistic graphical models is still very much a practical challenge in large domains. The commonly used and effective belief propagation (BP) algorithm and its generalizations often do not converge when applied to hard, real-life inference tasks. While it is widely recognized that the scheduling of messages in these algorithms may have significant consequences, this issue remains largely unexplored. In this work, we address the question of how to schedule messages for asynchronous propagation so that a fixed point is reached faster and more often. We first show that any reasonable asynchronous BP converges to a unique fixed point under conditions similar to those that guarantee convergence of synchronous BP. In addition, we show that the convergence rate of a simple round-robin schedule is at least as good as that of synchronous propagation. We then propose residual belief propagation (RBP), a novel, easy-to-implement, asynchronous propagation algorithm that schedules messages in an informed way, that pushes down a bound on the distance from the fixed point. Finally, we demonstrate the superiority of RBP over state-of-the-art methods for a variety of challenging synthetic and real-life problems: RBP converges significantly more often than other methods; and it significantly reduces running time until convergence, even when other methods converge.}, note={arXiv:1206.6837 [cs]}, author={Elidan, Gal and McGraw, Ian and Koller, Daphne}, year={2012}, month=jun }
 @phdthesis{Han_2023, address={Toronto, Canada}, title={Accelerating Belief Propagation with Hardware Speculative Parallelism}, school={University of Toronto}, author={Han, Leo}, year={2023}, month=apr }
 @phdthesis{Jeffrey_2019, title={A Hardware and Software Architecture for Pervasive Parallelism}, url={https://dspace.mit.edu/bitstream/handle/1721.1/128566/1220833661-MIT.pdf}, school={Massachusetts Institute of Technology}, author={Jeffrey, Mark}, year={2019}, month=oct }
 @article{Yan_Yang_Yang_Zhao_2023, title={Hierarchical Belief Propagation on Image Segmentation Pyramid}, volume={32}, ISSN={1057-7149, 1941-0042}, url={https://ieeexplore.ieee.org/document/10198437/}, DOI={10.1109/TIP.2023.3299192}, journal={IEEE Transactions on Image Processing}, author={Yan, Tingman and Yang, Xilian and Yang, Genke and Zhao, Qunfei}, year={2023}, pages={4432–4442} }
